# LiteLLM Gateway Configuration
# OpenAI-compatible API for Ollama models

model_list:
  # Small model for quick responses (phi3)
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: ollama/phi3:mini
      api_base: http://localhost:11434
      
  # Medium model for complex queries (llama3.1-8b)
  - model_name: gpt-4
    litellm_params:
      model: ollama/llama3.1:8b
      api_base: http://localhost:11434

# General settings
general_settings:
  master_key: ${LITELLM_MASTER_KEY}
  
litellm_settings:
  drop_params: true  # Drop unsupported params
  set_verbose: true  # Enable debug logging
  
router_settings:
  routing_strategy: simple-shuffle
  num_retries: 2
  timeout: 60
